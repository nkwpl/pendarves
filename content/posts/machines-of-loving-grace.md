---
title: "On Machines of Loving Grace"
date: "2025-02-20"
type: "essay"
topic: "AI"
excerpt: "The question is not whether AI will change everything. It is whether we will be ready when it does."
---

Richard Brautigan imagined a world where machines of loving grace watched over us — a cybernetic meadow where technology and nature existed in harmony. That was 1967. We are closer to his vision than most people realise, and further from it than the optimists would have you believe.

## The Current Moment

We are at an inflection point. The large language models that have emerged in the last three years represent something genuinely new — not artificial general intelligence, not sentience, but a form of capability that does not fit neatly into our existing categories.

They can write. They can reason, after a fashion. They can produce work that, in many domains, is indistinguishable from human output. And they are improving rapidly.

The mistake that most commentators make is to focus on what these systems cannot do. They cannot feel. They do not understand in the way that we understand. They hallucinate. All true, and all beside the point.

The point is that capability, once unleashed, does not wait for our philosophical frameworks to catch up. The spinning jenny did not pause while the weavers debated the ethics of automation.

## Three Scenarios

I see three possible futures, and our actions in the next decade will determine which one we inhabit.

**The first** is the optimistic scenario: AI as a tool of human flourishing. In this world, we use artificial intelligence to solve problems that have defeated us — disease, poverty, the coordination failures that prevent collective action. This is Brautigan's meadow, updated for the twenty-first century.

**The second** is the dystopian scenario: AI as a tool of concentration. In this world, the benefits of artificial intelligence accrue to a small number of actors — corporations, states, individuals — who use their advantage to consolidate power. This is not science fiction. It is the default trajectory of most powerful technologies.

**The third** is the muddled middle: AI as a tool of disruption without direction. In this world, artificial intelligence changes everything but improves nothing. Old structures collapse. New ones do not emerge. We get the costs of transformation without the benefits.

## What Determines the Outcome

The difference between these scenarios is not technological. It is institutional. The technology will advance regardless. What matters is whether we build institutions — legal, social, economic — that channel that advancement toward human flourishing.

This is harder than it sounds. Institution-building is slow. Technology is fast. And the people who are best positioned to build institutions are often the ones with the least incentive to do so.

But it is not impossible. We have done it before. The post-war settlement, for all its flaws, demonstrated that it is possible to channel technological power toward broadly shared prosperity. The question is whether we have the political will to do it again.

I believe we do. But the window is narrow, and it is closing.
